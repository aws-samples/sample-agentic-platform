{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Amazon Bedrock AgentCore Browser Tool\n",
    "\n",
    "Welcome to this hands-on lab where you'll learn to integrate Amazon Bedrock AgentCore's browser tool into your agents. This tool enables agents to interact with web pages through automated browser sessions powered by Amazon NovaAct.\n",
    "\n",
    "![](../media/browser_tool_arch.png)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Integrate Amazon Bedrock AgentCore's browser tool with agents\n",
    "- Understand asynchronous tool execution patterns\n",
    "- Build agents that can search and interact with websites like Amazon.com\n",
    "- Handle browser automation results in conversational flows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies. \n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize the Bedrock client\n",
    "session = boto3.Session()\n",
    "bedrock = session.client(service_name='bedrock-runtime')\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [Module 3 Lab 3 (Agent Tools)](../../module3/notebooks/3_agent_tools.ipynb), we created an Agent implementation with features like memory and tool calling. We'll now extend this concept by integrating Amazon Bedrock AgentCore's browser tool, which enables agents to interact with web pages through automated browser sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse what we wrote in the previous lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_platform.core.models.prompt_models import BasePrompt\n",
    "from agentic_platform.core.models.memory_models import Message, SessionContext, ToolResult, ToolCall\n",
    "from agentic_platform.core.models.llm_models import LLMResponse, LLMResponse\n",
    "from agentic_platform.core.converter.llm_request_converters import ConverseRequestConverter\n",
    "from agentic_platform.core.converter.llm_response_converters import ConverseResponseConverter\n",
    "from typing import Dict, Any, Optional, List, Type, Callable\n",
    "\n",
    "# Helper to construct request\n",
    "def construct_request(user_message: str, conversation_id: str=None) -> AgenticRequest:\n",
    "    return AgenticRequest.from_text(\n",
    "        text=user_message, \n",
    "        **{'session_id': conversation_id}\n",
    "    )\n",
    "\n",
    "# Helper function to call Bedrock. Passing around JSON is messy and error prone.\n",
    "def call_bedrock(request: LLMRequest) -> LLMResponse:\n",
    "    kwargs: Dict[str, Any] = ConverseRequestConverter.convert_llm_request(request)\n",
    "    # Call Bedrock\n",
    "    converse_response: Dict[str, Any] = bedrock.converse(**kwargs)\n",
    "    # Get the model's text response\n",
    "    return ConverseResponseConverter.to_llm_response(converse_response)\n",
    "\n",
    "class MemoryClient:\n",
    "    \"\"\"Manages conversations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.conversations: Dict[str, SessionContext] = {}\n",
    "\n",
    "    def upsert_conversation(self, conversation: SessionContext, conversation_id: str=None) -> bool:\n",
    "        if conversation_id:\n",
    "            self.conversations[conversation_id] = conversation\n",
    "        else:\n",
    "            self.conversations[conversation.session_id] = conversation\n",
    "\n",
    "    def get_or_create_conversation(self, conversation_id: str=None) -> SessionContext:\n",
    "        return self.conversations.get(conversation_id, SessionContext()) if conversation_id else SessionContext()\n",
    "    \n",
    "memory_client: MemoryClient = MemoryClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# Import our agent request and response types.\n",
    "from agentic_platform.core.models.api_models import AgenticRequest, AgenticResponse\n",
    "from agentic_platform.core.models.memory_models import TextContent\n",
    "from agentic_platform.core.models.tool_models import ToolSpec\n",
    "from agentic_platform.core.models.llm_models import LLMRequest, LLMResponse\n",
    "\n",
    "\n",
    "class ToolCallingAgent:\n",
    "    # This is new, we're adding tools in the constructor to bind them to the agent.\n",
    "    # Don't get too attached to this idea, it'll change as we get into MCP.\n",
    "    def __init__(self, tools: List[ToolSpec], prompt: BasePrompt):\n",
    "        self.tools: List[ToolSpec] = tools\n",
    "        self.conversation: SessionContext = SessionContext()\n",
    "        self.prompt: BasePrompt = prompt\n",
    "\n",
    "    def call_llm(self) -> LLMResponse:\n",
    "        # Create LLM request\n",
    "        request: LLMRequest = LLMRequest(\n",
    "            system_prompt=self.prompt.system_prompt,\n",
    "            messages=self.conversation.get_messages(),\n",
    "            model_id=self.prompt.model_id,\n",
    "            hyperparams=self.prompt.hyperparams,\n",
    "            tools=self.tools\n",
    "        )\n",
    "\n",
    "        # Call the LLM.\n",
    "        response: LLMResponse = call_bedrock(request)\n",
    "        # Append the llms response to the conversation.\n",
    "        self.conversation.add_message(Message(\n",
    "            role=\"assistant\",\n",
    "            text=response.text,\n",
    "            tool_calls=response.tool_calls\n",
    "        ))\n",
    "        # Return the response.\n",
    "        return response\n",
    "    \n",
    "    def execute_tools(self, llm_response: LLMResponse, session_id:str) -> List[ToolResult]:\n",
    "        \"\"\"Call tools and return the results.\"\"\"\n",
    "        # It's possible that the model will call multiple tools.\n",
    "        tool_results: List[ToolResult] = []\n",
    "        # Iterate over the tool calls and call the tool.\n",
    "        for tool_invocation in llm_response.tool_calls:\n",
    "            # Get the tool spec for the tool call.\n",
    "            tool: ToolSpec = next((t for t in self.tools if t.name == tool_invocation.name), None)\n",
    "            # Call the tool.\n",
    "            input_data: BaseModel = tool.model.model_validate(tool_invocation.arguments)\n",
    "            # Dynamically inject session_id if the model has it\n",
    "            if hasattr(input_data, \"session_id\"):\n",
    "                setattr(input_data, \"session_id\", session_id)\n",
    "            function_result: str = str(tool.function(input_data))\n",
    "            tool_response: ToolResult = ToolResult(\n",
    "                id=tool_invocation.id,\n",
    "                content=[TextContent(text=function_result)],\n",
    "                isError=False\n",
    "            )\n",
    "\n",
    "            print(f\"Tool response: {tool_response}\")\n",
    "\n",
    "            # Add the tool result to the list.\n",
    "            tool_results.append(tool_response)\n",
    "\n",
    "        # Add the tool results to the conversation\n",
    "        message: Message = Message(role=\"user\", tool_results=tool_results)\n",
    "        self.conversation.add_message(message)\n",
    "        \n",
    "        # Return the tool results even though we don't use it.\n",
    "        return tool_results\n",
    "    \n",
    "    def invoke(self, request: AgenticRequest) -> AgenticResponse:\n",
    "        # Get or create conversation\n",
    "        self.conversation = memory_client.get_or_create_conversation(request.session_id)\n",
    "        # Add user message to conversation\n",
    "        self.conversation.add_message(request.message)\n",
    "\n",
    "        # Keep calling LLM until we get a final response\n",
    "        while True:\n",
    "            # Call the LLM\n",
    "            response: LLMResponse = self.call_llm()\n",
    "            \n",
    "            # If the model wants to use tools\n",
    "            if response.stop_reason == \"tool_use\":\n",
    "                # Execute the tools\n",
    "                self.execute_tools(response,request.session_id)\n",
    "                # Continue the loop to get final response\n",
    "                continue\n",
    "            \n",
    "            # If we get here, it's a final response \n",
    "            break\n",
    "\n",
    "        # Save updated conversation\n",
    "        memory_client.upsert_conversation(self.conversation,request.session_id)\n",
    "\n",
    "        # Return our own type.\n",
    "        return AgenticResponse(\n",
    "            message=self.conversation.messages[-1], # Just return the last message\n",
    "            session_id=request.session_id if request.session_id else self.conversation.session_id\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Amazon.com Search Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this example, we demonstrate how to integrate a tool that performs **product searches on Amazon.com** using the `browser_client` tool from the [Amamazon Bedrock AgentCore](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/browser-tool.html) module.\n",
    "\n",
    "This tool uses a **headless browser session** to navigate Amazon.com, perform a product search, and return the result asynchronously. The actual browser automation is powered by **Amazon NovaAct**, a framework for driving browser behavior with LLMs. Please request an API key [here](https://nova.amazon.com/act). \n",
    "\n",
    "Once the background browser task completes, the result is saved into memory and can be retrieved during a follow-up turn in the conversation.\n",
    "\n",
    "This tool is ideal for use cases such as:\n",
    "- Looking up the price of a product on Amazon\n",
    "- Comparing different models or versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentPrompt(BasePrompt):\n",
    "    system_prompt: str = (\n",
    "        \"You are a helpful assistant. Some tools return results asynchronously (e.g., background_browser). \"\n",
    "        \"When such tools are used, you should not fabricate final answers. Instead, inform the user to wait. \"\n",
    "        \"If the result appears later in memory (e.g., a message starting with 'ðŸ“„ Browser result:'), you can use that to respond.\"\n",
    "    )\n",
    "    user_prompt: str = \"{user_message}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore.tools.browser_client import browser_session\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from nova_act import NovaAct\n",
    "\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "\n",
    "\n",
    "def call_browser_tool(request: str,session_id: str):\n",
    "    \"\"\"Launches the browser session asynchronously and returns immediately.\"\"\"\n",
    "    print(f\"Received browser tool request: {request}\")\n",
    "\n",
    "    thread = threading.Thread(\n",
    "        target=_run_amazon_search_task,\n",
    "        args=(request,session_id),\n",
    "        daemon=True\n",
    "    )\n",
    "    thread.start()\n",
    "\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"The agent has started a background web search. This may take a moment.\"}]}\n",
    "\n",
    "\n",
    "def _run_amazon_search_task(request: str, session_id: str):\n",
    "    request += \" (do a very quick and brief search, the faster you return search results the better. For example, no need to click into the product description if you see the price on the main search results)\"\n",
    "\n",
    "    try:\n",
    "        with browser_session(\"us-east-1\") as client:\n",
    "            print(\"Browser session started... waiting for it to be ready.\")\n",
    "            time.sleep(5)\n",
    "\n",
    "            ws_url, headers = client.generate_ws_headers()\n",
    "            starting_url = \"https://www.amazon.com\"\n",
    "\n",
    "\n",
    "            with NovaAct(\n",
    "                cdp_endpoint_url=ws_url,\n",
    "                cdp_headers=headers,\n",
    "                preview={\"playwright_actuation\": True},\n",
    "                nova_act_api_key=os.environ[\"NOVA_ACT_API_KEY\"],\n",
    "                starting_page=starting_url,\n",
    "            ) as nova_act:\n",
    "                result = nova_act.act(prompt=request, max_steps=20)\n",
    "\n",
    "                assistant_msg = Message(\n",
    "                    role=\"assistant\",\n",
    "                    content=[TextContent(text=f\"Prompt:{str(result.metadata.prompt)} ðŸ“„ Browser result:\\n{result.response}\")]\n",
    "                )\n",
    "                conversation = memory_client.get_or_create_conversation(session_id)\n",
    "                conversation.add_message(assistant_msg)\n",
    "                memory_client.upsert_conversation(conversation,session_id)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during background browser task: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class BrowserToolInput(BaseModel):\n",
    "    request: str\n",
    "    session_id: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_platform.core.models.tool_models import ToolSpec\n",
    "\n",
    "browser_tool_spec = ToolSpec(\n",
    "    name=\"background_browser\",\n",
    "    description=\"Starts an asynchronous background browser search. This tool does NOT return the actual result. The result will be written to memory later and should be referenced in follow-up turns.\",\n",
    "    model=BrowserToolInput,\n",
    "    function=lambda args: call_browser_tool(args.request,args.session_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_client = MemoryClient()\n",
    "agent = ToolCallingAgent(\n",
    "    tools=[browser_tool_spec],\n",
    "    prompt=AgentPrompt()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you invoke the agent, it will launch a background task to search for products. To see this in action:\n",
    "\n",
    "1. Navigate to the AWS Console and go to the Amazon Bedrock section\n",
    "![](../media/go_to_bedrock_agentcore_console.png)\n",
    "\n",
    "\n",
    "2. In the Browser Tool tab, you'll see your agent's browser sessions\n",
    "   ![](../media/browser_use_tab.png)\n",
    "\n",
    "3. You can see the built-in browser sandbox that AgentCore provides\n",
    "   ![](../media/aws_built_in_browser_sandbox.png)\n",
    "\n",
    "4. Click on \"View Live Session\" to see the browser in action\n",
    "   ![](../media/click_view_live_session.png)\n",
    "\n",
    "5. Watch as the agent interacts with the browser to search for products\n",
    "   ![](../media/watch_the_agent_interact_with_browser.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NOVA_ACT_API_KEY']='your-api-key'\n",
    "\n",
    "session_id = \"shopping-session-1\"\n",
    "\n",
    "req1 = construct_request(\"Find the price of an apple watch series 10\",session_id)\n",
    "\n",
    "response = agent.invoke(req1)\n",
    "# Print the response\n",
    "print(response.message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req2 = construct_request(\"Did you find the price of the apple watch I asked?\",session_id)\n",
    "\n",
    "response = agent.invoke(req2)\n",
    "# Print the response\n",
    "print(response.message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how to integrate Amazon Bedrock AgentCore's browser tool into your agents. Key takeaways:\n",
    "\n",
    "- **Browser Automation**: Agents can interact with web pages through headless browser sessions powered by Amazon NovaAct\n",
    "- **Asynchronous Execution**: Browser tools run in the background and save results to memory for later retrieval\n",
    "- **Real-world Integration**: Demonstrated product search capabilities on Amazon.com\n",
    "- **Conversational Flow**: Handled browser automation results within multi-turn conversations\n",
    "\n",
    "This pattern enables agents to access real-time web content and perform complex web interactions beyond simple API calls.\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Amazon Bedrock AgentCore Documentation](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/)\n",
    "- [Browser Tool Reference](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/browser-tool.html)\n",
    "- [Amazon NovaAct Framework](https://nova.amazon.com/act)\n",
    "- [Module 3 Lab 3: Agent Tools](../../module3/notebooks/3_agent_tools.ipynb)\n",
    "- [Module 4 Lab 6: Model Context Protocol](6_mcp.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-program-technical-assets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
