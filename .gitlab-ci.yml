# GitLab CI/CD Pipeline for Building and Pushing Container Images to AWS ECR
# Converted from GitHub Actions workflow

# ===== TASK 7: PIPELINE TRIGGER RULES =====

# ===== SUBTASK 7.1 & 7.2: Configure automatic and manual triggers =====
workflow:
  rules:
    # ===== SUBTASK 7.1: Automatic triggers =====
    # Configure push to main branch trigger
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "main"'
      when: always
    # Configure push to develop branch trigger
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "develop"'
      when: always
    # Configure version tag trigger (v*)
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_TAG =~ /^v.*/'
      when: always
    # Configure merge request trigger
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: always
    # ===== SUBTASK 7.2: Manual trigger =====
    # Configure workflow:manual rule with MANUAL_SERVICES variable input
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: always
      variables:
        # Define MANUAL_SERVICES variable input with default value "changed"
        MANUAL_SERVICES: "${MANUAL_SERVICES:-changed}"
    # ===== SUBTASK 7.3: Disabled state (commented out) =====
    # To disable automatic triggers and keep only manual triggering enabled,
    # comment out the automatic trigger rules above (lines for main, develop, tags, and merge requests)
    # and keep only the manual trigger rule (web pipeline source).
    # Example disabled configuration:
    # - if: '$CI_PIPELINE_SOURCE == "web"'
    #   when: always
    # Default: do not run for any other pipeline sources
    - when: never

# Define pipeline stages
stages:
  - detect-changes
  - build
  - summary

# Global variables
variables:
  AWS_REGION: "us-east-1"  # Default AWS region, can be overridden in GitLab CI/CD settings

# Default Docker image for all jobs
default:
  image: ubuntu:22.04
  before_script:
    - apt-get update -qq
    - apt-get install -y -qq git jq curl unzip
    - |
      # Install AWS CLI
      curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
      unzip -q awscliv2.zip
      ./aws/install
      rm -rf aws awscliv2.zip

# Placeholder jobs for each stage (to be implemented in subsequent tasks)

detect-changes:
  stage: detect-changes
  script:
    # ===== SUBTASK 2.4: AWS OIDC Authentication =====
    - echo "Authenticating with AWS using OIDC..."
    - |
      # Use GitLab's CI_JOB_JWT_V2 token for OIDC authentication
      CREDENTIALS=$(aws sts assume-role-with-web-identity \
        --role-arn ${AWS_ROLE_ARN} \
        --role-session-name "gitlab-ci-${CI_PROJECT_NAME}-${CI_PIPELINE_ID}" \
        --web-identity-token ${CI_JOB_JWT_V2} \
        --duration-seconds 3600 \
        --query 'Credentials.[AccessKeyId,SecretAccessKey,SessionToken]' \
        --output text)
      
      # Export AWS credentials as environment variables
      export AWS_ACCESS_KEY_ID=$(echo $CREDENTIALS | awk '{print $1}')
      export AWS_SECRET_ACCESS_KEY=$(echo $CREDENTIALS | awk '{print $2}')
      export AWS_SESSION_TOKEN=$(echo $CREDENTIALS | awk '{print $3}')
      
      # Configure AWS CLI with credentials
      aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
      aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
      aws configure set aws_session_token $AWS_SESSION_TOKEN
      aws configure set region ${AWS_REGION}
      
      echo "AWS authentication successful"
    
    # ===== SUBTASK 2.2: Service Auto-Discovery =====
    - echo "Discovering services from src/agentic_platform/agent/ directory..."
    - |
      # Initialize empty array for services
      ALL_SERVICES=()
      
      # Scan src/agentic_platform/agent/ directory for subdirectories with Dockerfiles
      if [ -d "src/agentic_platform/agent" ]; then
        for service_dir in src/agentic_platform/agent/*/; do
          # Check if Dockerfile exists in subdirectory
          if [ -f "${service_dir}Dockerfile" ]; then
            # Extract service name from directory basename
            service_name=$(basename "$service_dir")
            ALL_SERVICES+=("$service_name")
          fi
        done
      fi
      
      # Also check docker/ directory as fallback
      if [ -d "docker" ]; then
        for service_dir in docker/*/; do
          # Check if Dockerfile exists in subdirectory
          if [ -f "${service_dir}Dockerfile" ]; then
            # Extract service name from directory basename
            service_name=$(basename "$service_dir")
            ALL_SERVICES+=("$service_name")
          fi
        done
      fi
        
        # Sort services for consistent output
        IFS=$'\n' ALL_SERVICES=($(sort <<<"${ALL_SERVICES[*]}"))
        unset IFS
        
        # Log discovered services
        echo "Discovered ${#ALL_SERVICES[@]} services:"
        for service in "${ALL_SERVICES[@]}"; do
          echo "  - $service"
        done
      
      if [ ${#ALL_SERVICES[@]} -eq 0 ]; then
        echo "No services found with Dockerfiles."
      fi
    
    # ===== SUBTASK 2.9: Manual Trigger Parameter Handling =====
    - |
      # Initialize services to build array
      SERVICES_TO_BUILD=()
      
      # Check for MANUAL_SERVICES variable
      if [ -n "${MANUAL_SERVICES:-}" ]; then
        echo "Manual trigger detected with parameter: ${MANUAL_SERVICES}"
        
        # Handle "all" parameter
        if [ "${MANUAL_SERVICES}" = "all" ]; then
          echo "Building all discovered services"
          SERVICES_TO_BUILD=("${ALL_SERVICES[@]}")
        
        # Handle "changed" parameter (use change detection)
        elif [ "${MANUAL_SERVICES}" = "changed" ]; then
          echo "Using change detection for manual trigger"
          # Will be populated by change detection logic below
          
        # Handle comma-separated list
        else
          echo "Parsing comma-separated service list"
          IFS=',' read -ra MANUAL_SERVICE_LIST <<< "${MANUAL_SERVICES}"
          for service in "${MANUAL_SERVICE_LIST[@]}"; do
            # Trim whitespace
            service=$(echo "$service" | xargs)
            # Validate service exists in discovered services
            if [[ " ${ALL_SERVICES[@]} " =~ " ${service} " ]]; then
              SERVICES_TO_BUILD+=("$service")
            else
              echo "Warning: Service '$service' not found in discovered services, skipping"
            fi
          done
        fi
      fi
    
    # ===== SUBTASK 2.7: Change Detection Logic =====
    - |
      # Only run change detection if not manually triggered with "all" or specific list
      if [ ${#SERVICES_TO_BUILD[@]} -eq 0 ]; then
        echo "Running change detection..."
        
        # Determine trigger type and get appropriate commit SHAs
        if [ -n "${CI_MERGE_REQUEST_IID:-}" ]; then
          # Merge request trigger
          echo "Trigger type: Merge Request"
          BASE_SHA="${CI_MERGE_REQUEST_TARGET_BRANCH_SHA}"
          HEAD_SHA="${CI_COMMIT_SHA}"
        elif [ "${CI_COMMIT_BEFORE_SHA}" = "0000000000000000000000000000000000000000" ]; then
          # New branch or first commit
          echo "Trigger type: New branch (building all services)"
          BASE_SHA=""
          HEAD_SHA="${CI_COMMIT_SHA}"
        else
          # Regular push
          echo "Trigger type: Push"
          BASE_SHA="${CI_COMMIT_BEFORE_SHA}"
          HEAD_SHA="${CI_COMMIT_SHA}"
        fi
        
        echo "Comparing commits: ${BASE_SHA:-<none>} -> ${HEAD_SHA}"
        
        # Get changed files using git diff
        if [ -n "${BASE_SHA}" ]; then
          CHANGED_FILES=$(git diff --name-only ${BASE_SHA} ${HEAD_SHA} || echo "")
        else
          # For new branches, consider all files as changed
          CHANGED_FILES=$(git ls-files || echo "")
        fi
        
        echo "Changed files:"
        echo "$CHANGED_FILES"
        
        # Check for core dependency changes
        CORE_CHANGED=false
        CORE_PATTERNS=(
          "pyproject.toml"
          "requirements.txt"
          "src/agentic_platform/core/"
          "package.json"
          "yarn.lock"
        )
        
        for pattern in "${CORE_PATTERNS[@]}"; do
          if echo "$CHANGED_FILES" | grep -q "$pattern"; then
            echo "Core dependency change detected: $pattern"
            CORE_CHANGED=true
            break
          fi
        done
        
        # If core changed, build all services
        if [ "$CORE_CHANGED" = true ]; then
          echo "Core dependencies changed - marking all services for rebuild"
          SERVICES_TO_BUILD=("${ALL_SERVICES[@]}")
        else
          # Check for service-specific changes
          for service in "${ALL_SERVICES[@]}"; do
            # Handle hyphen/underscore variations
            service_underscore=$(echo "$service" | tr '-' '_')
            service_hyphen=$(echo "$service" | tr '_' '-')
            
            # Check service-specific directories
            if echo "$CHANGED_FILES" | grep -q "docker/${service}/\|docker/${service_underscore}/\|docker/${service_hyphen}/"; then
              echo "Changes detected in docker/${service}/"
              SERVICES_TO_BUILD+=("$service")
            elif echo "$CHANGED_FILES" | grep -q "src/agentic_platform/service/${service}/\|src/agentic_platform/service/${service_underscore}/\|src/agentic_platform/service/${service_hyphen}/"; then
              echo "Changes detected in src/agentic_platform/service/${service}/"
              SERVICES_TO_BUILD+=("$service")
            elif echo "$CHANGED_FILES" | grep -q "src/agentic_platform/agent/${service}/\|src/agentic_platform/agent/${service_underscore}/\|src/agentic_platform/agent/${service_hyphen}/"; then
              echo "Changes detected in src/agentic_platform/agent/${service}/"
              SERVICES_TO_BUILD+=("$service")
            fi
          done
        fi
      fi
    
    # ===== SUBTASK 2.6: ECR Repository Validation =====
    - |
      echo "Validating ECR repositories..."
      MISSING_REPO_SERVICES=()
      
      for service in "${ALL_SERVICES[@]}"; do
        # Use naming pattern "agentic-platform-{service}"
        repo_name="agentic-platform-${service}"
        
        # Query AWS ECR for repository
        if aws ecr describe-repositories --repository-names "$repo_name" --region ${AWS_REGION} >/dev/null 2>&1; then
          echo "ECR repository exists: $repo_name"
        else
          echo "ECR repository missing: $repo_name"
          MISSING_REPO_SERVICES+=("$service")
        fi
      done
      
      if [ ${#MISSING_REPO_SERVICES[@]} -gt 0 ]; then
        echo "Services with missing ECR repositories:"
        for service in "${MISSING_REPO_SERVICES[@]}"; do
          echo "  - $service"
        done
      fi
    
    # ===== SUBTASK 2.11: Build List Generation and Deduplication =====
    - |
      echo "Generating final build list..."
      
      # Combine changed services and missing repository services
      COMBINED_SERVICES=("${SERVICES_TO_BUILD[@]}" "${MISSING_REPO_SERVICES[@]}")
      
      # Remove duplicates and sort
      FINAL_SERVICES=($(printf '%s\n' "${COMBINED_SERVICES[@]}" | sort -u))
      
      # Log reasons for building each service
      echo "Final build list (${#FINAL_SERVICES[@]} services):"
      for service in "${FINAL_SERVICES[@]}"; do
        reasons=()
        
        # Check if in changed services
        if [[ " ${SERVICES_TO_BUILD[@]} " =~ " ${service} " ]]; then
          reasons+=("code changes")
        fi
        
        # Check if in missing repo services
        if [[ " ${MISSING_REPO_SERVICES[@]} " =~ " ${service} " ]]; then
          reasons+=("missing ECR repository")
        fi
        
        echo "  - $service (${reasons[*]})"
      done
      
      # Generate JSON array of services
      if [ ${#FINAL_SERVICES[@]} -gt 0 ]; then
        SERVICES_JSON=$(printf '%s\n' "${FINAL_SERVICES[@]}" | jq -R . | jq -s -c .)
      else
        SERVICES_JSON="[]"
      fi
      
      echo "Services JSON: $SERVICES_JSON"
      
      # Write to dotenv artifact file
      echo "SERVICES_TO_BUILD=$SERVICES_JSON" > build.env
      echo "BUILD_COUNT=${#FINAL_SERVICES[@]}" >> build.env
      
      echo "Build configuration written to build.env"
      cat build.env
  
  artifacts:
    reports:
      dotenv: build.env
    paths:
      - build.env
    expire_in: 1 hour
  
  # Configure OIDC authentication variables
  id_tokens:
    CI_JOB_JWT_V2:
      aud: https://gitlab.com

build:
  stage: build
  image: docker:24-dind
  services:
    - docker:24-dind
  variables:
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_CERTDIR: "/certs"
    DOCKER_TLS_VERIFY: 1
    DOCKER_CERT_PATH: "$DOCKER_TLS_CERTDIR/client"
  before_script:
    # Install AWS CLI and other tools in Docker image
    - apk add --no-cache python3 py3-pip bash jq curl aws-cli
  needs:
    - job: detect-changes
      artifacts: true
  # Configure OIDC authentication variables
  id_tokens:
    CI_JOB_JWT_V2:
      aud: https://gitlab.com
  # Skip if no services to build
  rules:
    - if: '$BUILD_COUNT == "0"'
      when: never
    - when: on_success
  script:
    # ===== SUBTASK 4.1 & 4.2: AWS OIDC Authentication and Build Services =====
    - |
      cat > /tmp/build.sh << 'EOFSCRIPT'
      #!/bin/bash
      set -e
      
      echo "Authenticating with AWS using OIDC..."
      
      # Use GitLab CI_JOB_JWT_V2 token for OIDC authentication
      CREDENTIALS=$(aws sts assume-role-with-web-identity \
        --role-arn ${AWS_ROLE_ARN} \
        --role-session-name "gitlab-ci-${CI_PROJECT_NAME}-${CI_PIPELINE_ID}" \
        --web-identity-token ${CI_JOB_JWT_V2} \
        --duration-seconds 3600 \
        --query 'Credentials.[AccessKeyId,SecretAccessKey,SessionToken]' \
        --output text)
      
      # Export AWS credentials as environment variables
      export AWS_ACCESS_KEY_ID=$(echo $CREDENTIALS | awk '{print $1}')
      export AWS_SECRET_ACCESS_KEY=$(echo $CREDENTIALS | awk '{print $2}')
      export AWS_SESSION_TOKEN=$(echo $CREDENTIALS | awk '{print $3}')
      
      # Configure AWS CLI with credentials
      aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
      aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
      aws configure set aws_session_token $AWS_SESSION_TOKEN
      aws configure set region ${AWS_REGION}
      
      echo "AWS authentication successful"
      
      # ===== SUBTASK 4.2: Parallel Matrix Configuration =====
      # Parse services from JSON array and build in parallel using background jobs
      echo "Parsing services to build from artifact..."
      echo "SERVICES_TO_BUILD: $SERVICES_TO_BUILD"
      
      # Check if services list is empty
      if [ "$SERVICES_TO_BUILD" = "[]" ] || [ -z "$SERVICES_TO_BUILD" ]; then
        echo "No services to build. Exiting successfully."
        exit 0
      fi
      
      # Parse JSON array into bash array
      SERVICES=($(echo "$SERVICES_TO_BUILD" | jq -r '.[]'))
      
      echo "Services to build in parallel: ${SERVICES[@]}"
      
      # Create array to track background job PIDs
      declare -a BUILD_PIDS
      declare -a BUILD_SERVICES
      
      # Function to build a single service
      build_service() {
        local service=$1
        echo "========================================="
        echo "Building service: $service"
        echo "========================================="
        
        # ===== SUBTASK 4.4: Build Script Execution =====
        
        # Make build script executable
        chmod +x deploy/build-container-gitlab.sh
        
        # Execute script with service name parameter
        echo "Executing: ./deploy/build-container-gitlab.sh $service"
        ./deploy/build-container-gitlab.sh "$service"
        
        # Capture and propagate exit code
        local exit_code=$?
        
        if [ $exit_code -eq 0 ]; then
          echo "Build script completed successfully for service: $service"
        else
          echo "Build script failed for service: $service (exit code: $exit_code)"
        fi
        
        return $exit_code
      }
      
      # Launch builds in parallel
      for service in "${SERVICES[@]}"; do
        echo "Launching parallel build for service: $service"
        (
          build_service "$service"
          exit $?
        ) &
        BUILD_PIDS+=($!)
        BUILD_SERVICES+=("$service")
      done
      
      # Wait for all builds to complete and collect results
      echo ""
      echo "Waiting for all parallel builds to complete..."
      FAILED_BUILDS=()
      SUCCESS_BUILDS=()
      
      for i in "${!BUILD_PIDS[@]}"; do
        pid=${BUILD_PIDS[$i]}
        service=${BUILD_SERVICES[$i]}
        
        if wait $pid; then
          echo "âœ“ Build succeeded for service: $service"
          SUCCESS_BUILDS+=("$service")
        else
          echo "âœ— Build failed for service: $service"
          FAILED_BUILDS+=("$service")
        fi
      done
      
      # Report results
      echo ""
      echo "========================================="
      echo "Build Results Summary"
      echo "========================================="
      echo "Total services: ${#SERVICES[@]}"
      echo "Successful builds: ${#SUCCESS_BUILDS[@]}"
      echo "Failed builds: ${#FAILED_BUILDS[@]}"
      
      if [ ${#FAILED_BUILDS[@]} -gt 0 ]; then
        echo ""
        echo "Failed services:"
        for service in "${FAILED_BUILDS[@]}"; do
          echo "  - $service"
        done
        echo ""
        echo "Build stage failed due to one or more service build failures"
        exit 1
      else
        echo ""
        echo "All service builds completed successfully!"
        exit 0
      fi
      EOFSCRIPT
    - chmod +x /tmp/build.sh
    - /bin/bash /tmp/build.sh

# ===== TASK 6: SUMMARY STAGE =====

summary:
  stage: summary
  # ===== SUBTASK 6.1: Create summary job definition =====
  # Configure dependencies on detect-changes and build jobs
  needs:
    - job: detect-changes
      artifacts: true
    - job: build
      optional: true  # Build job may be skipped if no services to build
  # Set when: always to run even on failures
  when: always
  
  script:
    # ===== SUBTASK 6.2: Implement summary generation logic =====
    - |
      #!/bin/bash
      set -e
      
      echo "========================================="
      echo "Pipeline Build Summary"
      echo "========================================="
      echo ""
      
      # Read services list from artifact
      if [ -f "build.env" ]; then
        source build.env
        
        # Check if list is empty
        if [ "$BUILD_COUNT" = "0" ] || [ "$SERVICES_TO_BUILD" = "[]" ]; then
          # Generate appropriate message for empty list
          echo "ðŸ“‹ Result: No services were built"
          echo ""
          echo "Reason: No code changes detected and all ECR repositories exist."
          echo ""
          echo "The pipeline completed successfully with no build actions required."
        else
          # Generate list of built services
          echo "ðŸ“¦ Services Built: $BUILD_COUNT"
          echo ""
          
          # Parse and format the services list - use jq properly
          echo "The following services were processed:"
          printf '%s\n' "$SERVICES_TO_BUILD" | jq -r '.[]' | while read -r service; do
            echo "  âœ“ $service"
          done
          
          echo ""
          echo "All container images have been built and pushed to AWS ECR."
        fi
      else
        echo "âš ï¸  Warning: build.env artifact not found"
        echo ""
        echo "Unable to generate detailed summary. The detect-changes job may have failed."
      fi
      
      echo ""
      echo "========================================="
      echo "Pipeline execution completed"
      echo "========================================="
